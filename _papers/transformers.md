---
title: "Attention Is All You Need"
authors:
  - Ashish Vaswani
  - Noam Shazeer
  - Niki Parmar
  - Jakob Uszkoreit
  - Llion Jones
year: 2017
arxiv: "1706.03762"
category: machine-learning
tags: [transformers, attention, nlp, deep-learning]
date_added: 2024-01-15
summary: |
  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.
---
