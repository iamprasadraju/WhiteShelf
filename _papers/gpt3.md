---
title: "Language Models are Few-Shot Learners"
authors:
  - Tom Brown
  - Benjamin Mann
  - Nick Ryder
year: 2020
arxiv: "2005.14165"
category: machine-learning
tags: [language-models, few-shot, gpt]
date_added: 2024-01-20
summary: |
  We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance. GPT-3 achieves strong performance on many NLP datasets without any gradient updates.
---
