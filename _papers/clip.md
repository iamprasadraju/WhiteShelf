---
title: "Learning Transferable Visual Models From Natural Language Supervision"
authors:
  - Alec Radford
  - Jong Wook Kim
  - Chris Hallacy
year: 2021
arxiv: "2103.00020"
category: computer-vision
tags: [vision-language, multimodal, zero-shot, clip]
date_added: 2024-02-10
summary: |
  We train a vision model on natural language supervision without classic labeled datasets. CLIP matches ImageNet performance without using any of the 1.28M training examples.
---
